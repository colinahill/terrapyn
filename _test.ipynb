{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import terrapyn as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "# from terrapyn.scoring import metrics, grouped_scores, score_df, ConfusionMatrix\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.geo.geobox import GeoBox\n",
    "from odc.geo.geom import Geometry\n",
    "import  odc.geo.xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_client = tp.dask_utils.create_cluster_and_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\n",
    "    # 'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3',\n",
    "    'gs://gcp-public-data-arco-era5/co/single-level-reanalysis.zarr-v2',\n",
    "\n",
    "    chunks=None,\n",
    "    # chunks={'time': 48},\n",
    "    storage_options=dict(token='anon'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['t2m'].isel(time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime(1980, 1, 1)\n",
    "end_date = dt.datetime(1980, 12, 31)\n",
    "# end_date = dt.datetime(2009, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_t2m = ds['2m_temperature'].sel(time=slice(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sub = ds_t2m.sel(latitude=43, longitude=6, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sub = ds_sub.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sub = tp.conversion.kelvin_to_celsius(ds_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daily = tp.time.resample_time(ds_sub, freq='1D', resample_method='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daily.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon = odc.geo.geom.box(left=0, bottom=40, right=10, top=46, crs='EPSG:4326')\n",
    "geobox = GeoBox.from_geopolygon(geopolygon, resolution=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_t2m_sub = tp.space.crop(ds_t2m, geopolygon=geopolygon, lon_name='longitude', lat_name='latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_plot = ds_t2m_sub.sel(time=start_date).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_plot.plot();\n",
    "# ds_plot#.isel(time=0).where(da_lsm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lsm = ds['land_sea_mask'].isel(time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD_TIME_DIMS = [\"time\", \"date\"]\n",
    "# from typing import Optional, Tuple, Union\n",
    "# import xarray\n",
    "# def time_dim(\n",
    "#     xx: Union[xarray.DataArray, xarray.Dataset], relaxed: bool = False\n",
    "# ) -> Optional[Tuple[str, str]]:\n",
    "#     \"\"\"\n",
    "#     Find time dimensions of ``xx``.\n",
    "\n",
    "#     Checks for presence of dimensions named: ``time | date``\n",
    "\n",
    "#     If ``relaxed=True`` and none of the above dimension names are found,\n",
    "#     assume that the last dimension is time.\n",
    "\n",
    "#     :returns: ``None`` if no dimensions with expected names are found\n",
    "#     :returns: ``'time' | 'date'``\n",
    "#     \"\"\"\n",
    "#     _dims = [str(dim) for dim in xx.dims]\n",
    "#     guess = [dim for dim in _dims if dim in STANDARD_TIME_DIMS]\n",
    "#     if guess:\n",
    "#         return guess[0]\n",
    "\n",
    "#     # Assume data has at least latitude, longitude and time\n",
    "#     # dimensions, where time is the last\n",
    "#     if relaxed and len(_dims) >= 2:\n",
    "#         return _dims[-1]\n",
    "\n",
    "#     return None\n",
    "# rasterized = odc.geo._xr_interop.rasterize(\n",
    "#         poly=geopolygon,\n",
    "#         how=xx.odc.geobox,\n",
    "#         all_touched=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terrapyn import TEST_DATA_DIR\n",
    "data = xr.open_dataset(TEST_DATA_DIR / \"lat_10_lon_10_time_10_D_test_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.expand_dims({'band':['a', 'b']}, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_coords({'band':['a', 'b']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon = odc.geo.geom.box(left=12.3, bottom=3.3, right=14.4, top=5.7, crs='EPSG:4326')\n",
    "geopolygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.odc.assign_crs(crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = data.odc.crop(poly=geopolygon, apply_mask=False)\n",
    "xx = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = odc.geo.xr.crop(xx, geopolygon, all_touched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked#.sel(band='b').isel(time=5)['var'].plot.imshow();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat rasterized mask across all non-spatial dims\n",
    "    sdims = spatial_dims(xx, relaxed=True)\n",
    "    non_sdims = {}\n",
    "    non_sdims_axis = []\n",
    "    for i, (k, v) in enumerate(xx.sizes.items()):\n",
    "        if k not in sdims:\n",
    "            non_sdims[k] = v\n",
    "            non_sdims_axis.append(i)\n",
    "    if non_sdims:\n",
    "        rasterized = rasterized.expand_dims(non_sdims, axis=non_sdims_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spatial dims then broadcast mask across all remaining dims\n",
    "from odc.geo._xr_interop import spatial_dims, rasterize\n",
    "import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(\n",
    "    xx, poly: Geometry, invert: bool = False, all_touched: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply a polygon geometry as a mask, setting all\n",
    "    :py:class:`xarray.Dataset` or :py:class:`xarray.DataArray` pixels\n",
    "    outside the rasterized polygon to ``NaN``.\n",
    "\n",
    "    :param xx:\n",
    "       :py:class:`~xarray.Dataset` or :py:class:`~xarray.DataArray`.\n",
    "\n",
    "    :param poly:\n",
    "       A :py:class:`odc.geo.geom.Geometry` polygon used to mask ``xx``.\n",
    "\n",
    "    :param invert:\n",
    "        Whether to invert the mask before applying it to ``xx``. If\n",
    "        ``True``, only pixels inside of ``poly`` will be masked.\n",
    "\n",
    "    :param all_touched:\n",
    "        If ``True``, the rasterize step will burn in all pixels touched\n",
    "        by ``poly``. If ``False``, only pixels whose centers are within\n",
    "        the polygon or that are selected by Bresenham's line algorithm\n",
    "        will be burned in.\n",
    "\n",
    "    :return:\n",
    "        A :py:class:`~xarray.Dataset` or :py:class:`~xarray.DataArray`\n",
    "        masked by ``poly``.\n",
    "\n",
    "    .. seealso:: :py:meth:`odc.geo.xr.rasterize`\n",
    "    \"\"\"\n",
    "    # Rasterise `poly` into geobox of `xx`\n",
    "    rasterized = rasterize(\n",
    "        poly=poly,\n",
    "        how=xx.odc.geobox,\n",
    "        all_touched=all_touched,\n",
    "        value_inside=not invert,\n",
    "    )\n",
    "\n",
    "    # Repeat rasterized mask across all non-spatial dims\n",
    "    sdims = spatial_dims(xx, relaxed=True)\n",
    "    non_sdims = {}\n",
    "    non_sdims_axis = []\n",
    "    for i, (k, v) in enumerate(xx.sizes.items()):\n",
    "        if k not in sdims:\n",
    "            non_sdims[k] = v\n",
    "            non_sdims_axis.append(i)\n",
    "    if non_sdims:\n",
    "        rasterized = rasterized.expand_dims(non_sdims, axis=non_sdims_axis)\n",
    "\n",
    "    # Mask data outside rasterized `poly`\n",
    "    xx_masked = xx.where(rasterized.data)\n",
    "\n",
    "    # Remove nodata attribute from arrays\n",
    "    if isinstance(xx_masked, xarray.Dataset):\n",
    "        for var in xx_masked.data_vars:\n",
    "            xx_masked[var].attrs.pop(\"nodata\", None)\n",
    "    else:\n",
    "        xx_masked.attrs.pop(\"nodata\", None)\n",
    "\n",
    "    return xx_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdims = spatial_dims(xx, relaxed=True)\n",
    "sdims\n",
    "# non_sdims = {k:v for k, v in xx.sizes.items() if k not in sdims}\n",
    "\n",
    "non_sdims = {}\n",
    "non_sdims_axis = []\n",
    "for i, (k, v) in enumerate(xx.sizes.items()):\n",
    "    if k not in sdims:\n",
    "        non_sdims[k] = v\n",
    "        non_sdims_axis.append(i)\n",
    "non_sdims, non_sdims_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert: bool = False\n",
    "all_touched: bool = True\n",
    "rasterized = rasterize(\n",
    "        poly=geopolygon,\n",
    "        how=xx.odc.geobox,\n",
    "        all_touched=all_touched,\n",
    "        value_inside=not invert,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat rasterized mask across all non-spatial dims\n",
    "rasterized = rasterized.expand_dims(non_sdims, axis=non_sdims_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.space.crop(ds, geopolygon=geopolygon, )#[\"var\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon = odc.geo.geom.box(left=0, bottom=0, right=25, top=4, crs='EPSG:4326')\n",
    "geobox = GeoBox.from_geopolygon(geopolygon, resolution=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.geo.xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = odc.geo.xr.rasterize(geopolygon, how=1).rename({'latitude': 'lat', 'longitude': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.values = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame(\n",
    "            {\n",
    "                \"time\": pd.date_range(\"2019-03-15\", freq=\"1D\", periods=3),\n",
    "                \"id\": [123, 456, 789],\n",
    "                \"lat\": [1, 3, 5],\n",
    "                \"lon\": [10, 20, 30],\n",
    "            }\n",
    "        ).set_index([\"time\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.space.crop(df, geopolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gpd.read_parquet('/Users/chill/software/regrowag/weather-analysis/data/boundaries.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_world = tp.space.generate_grid(return_type='dataarray', resolution=1, fill_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely_geometry = b.iloc[0].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon = Geometry(shapely_geometry, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geobox = GeoBox.from_geopolygon(geopolygon, resolution=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T\n",
    "import odc.geo.xr\n",
    "from terrapyn.space import get_lat_lon_from_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid(\n",
    "    geobox: BBox = None,\n",
    "    resolution: float = 1.0,\n",
    "    min_lat: float = -90,\n",
    "    max_lat: float = 90,\n",
    "    min_lon: float = -180,\n",
    "    max_lon: float = 180,\n",
    "    return_type: str = \"dataarray\",\n",
    "    fill_value: T.Union[int, float] = None,\n",
    ") -> T.Union[T.Tuple[np.ndarray, np.ndarray], xr.DataArray, xr.Dataset]:\n",
    "    \"\"\"\n",
    "    Makes an xr.DataArray/xr.Dataset grid with optional variable and fill value.\n",
    "\n",
    "    Args:\n",
    "        resolution: Resolution (in degrees).\n",
    "        bbox: Optional Bounding box for data. Takes precedence over other coordinates.\n",
    "        min_lat: Lower latitude.\n",
    "        max_lat: Upper latitude.\n",
    "        min_lon: Lower longitude.\n",
    "        max_lon: Upper longitude.\n",
    "        return_type: Type of object to return; 'numpy' for arrays of latitude, longitude, 'dataarray' for Xarray DataArray.\n",
    "        fill_value: Value used to fill the grid. Defaults to `np.nan` if `fill_value` is `None`.\n",
    "\n",
    "    Returns:\n",
    "        Arrays or DataArray with the given coordinates, with optional fill value.\n",
    "    \"\"\"\n",
    "    if bbox:\n",
    "        max_lat, min_lon, min_lat, max_lon = bbox.NWSE\n",
    "    lats = np.arange(min_lat, max_lat + resolution, resolution)\n",
    "    lons = np.arange(min_lon, max_lon + resolution, resolution)\n",
    "\n",
    "    if return_type == \"numpy\":\n",
    "        return lats, lons\n",
    "\n",
    "    if fill_value:\n",
    "        data = np.full(shape=(lats.shape[0], lons.shape[0]), fill_value=fill_value)\n",
    "    else:\n",
    "        data = np.nan\n",
    "\n",
    "    da = xr.DataArray(data=data, coords={\"lat\": lats, \"lon\": lons}, dims=[\"lat\", \"lon\"])\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = da_world.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.to_dataframe('val').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = data.to_dataframe('val').copy()\n",
    "gdf.reset_index(inplace=True)\n",
    "gdf['geometry'] = gpd.points_from_xy(gdf['lon'], gdf['lat'])\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.set_crs(\"EPSG:4326\")\n",
    "gdf = gdf.to_crs('epsg:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(data=df, geopolygon=geopolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs=\"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.odc.assign_crs(crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(data, 'spatial_ref'):\n",
    "    data = data.odc.assign_crs(crs=crs)\n",
    "return data.odc.crop(poly=geopolygon, apply_mask=apply_mask, all_touched=all_touched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geopolygon = Geometry(geom, crs=\"EPSG:4326\")\n",
    "# Mask data to set pixels outside polygon to NaN\n",
    "# da_masked = da.odc.mask(poly=geopolygon)\n",
    "# Crop data to extent of polygon (and optionally mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "da = odc.geo.xr.assign_crs(da, crs=\"EPSG:4326\")\n",
    "# geopolygon = Geometry(geom, crs=\"EPSG:4326\")\n",
    "# Mask data to set pixels outside polygon to NaN\n",
    "# da_masked = da.odc.mask(poly=geopolygon)\n",
    "# Crop data to extent of polygon (and optionally mask)\n",
    "da_cropped = da.odc.crop(poly=geopolygon, apply_mask=True)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geobox.boundingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = tp.space.BBox(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lon, min_lat, max_lon, max_lat = geobox.boundingbox.bbox\n",
    "geobox.boundingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = tp.space.generate_grid(max_lon=max_lon, max_lat=max_lat, min_lat=min_lat, min_lon=min_lon, \n",
    "                            return_type='dataarray', \n",
    "                            # bbox=bbox, \n",
    "                            resolution=0.1, fill_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = da.to_dataset(name='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds['b'] = da['a'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoBox.from_bbox(bbox=(102.12744140625, 8.583251953125, 109.44492187500003, 23.34521484375), crs='EPSG:4326', resolution=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geobox = GeoBox.from_geopolygon(geopolygon, resolution=0.01)\n",
    "# geobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = odc.geo.xr.assign_crs(da, crs=\"EPSG:4326\")\n",
    "# geopolygon = Geometry(geom, crs=\"EPSG:4326\")\n",
    "# Mask data to set pixels outside polygon to NaN\n",
    "# da_masked = da.odc.mask(poly=geopolygon)\n",
    "# Crop data to extent of polygon (and optionally mask)\n",
    "da_cropped = da.odc.crop(poly=geopolygon, apply_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_cropped.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeoBox.from_geopolygon(geom, resolution=(0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geobox = GeoBox.from_bbox(\n",
    "   (-2_000_000, -5_000_000,\n",
    "   2_250_000, -1_000_000),\n",
    "   \"epsg:3577\", resolution=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geobox.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.random.uniform(-180, 180, 100)\n",
    "lats = np.random.uniform(-90, 90, 100)\n",
    "# sine and cos of lats and lons\n",
    "values = np.sin(np.pi/180 *lons) * np.cos(np.pi/180 *lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilats, ilons = tp.space.generate_grid(return_type='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=lons, y=lats, c=values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tp.space.inverse_distance_weighting(lons=lons, lats=lats, values=values, lons_out=ilons, lats_out=ilats, p=2, return_type='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(ilons, ilats, z, levels=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_lat = 4\n",
    "n_lon = 4\n",
    "n_time = 3\n",
    "data = 5 + np.random.randn(n_time, n_lat, n_lon)\n",
    "da = xr.DataArray(\n",
    "    data,\n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    coords={\n",
    "        \"time\": pd.date_range(\"2014-09-06\", periods=n_time),\n",
    "        \"lat\": 3 + np.arange(n_lat),\n",
    "        \"lon\": 13 + np.arange(n_lon),\n",
    "    },\n",
    "    name=\"var\",\n",
    ")\n",
    "ds = da.to_dataset()\n",
    "df = ds.to_dataframe().rename(columns={\"var\": \"var1\"})\n",
    "df[\"var2\"] = df[\"var1\"] * 0.9\n",
    "df[\"var3\"] = df[\"var1\"] * 0.8\n",
    "df[\"var4\"] = df[\"var1\"] * 0.7\n",
    "df[\"model\"] = df[\"var1\"] * 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.scoring.score_df(df, metric='me', model_names=\"var1\", obs_names=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"me\", \"mae\", \"rmse\"]\n",
    "df_list = []\n",
    "for metric in metrics:\n",
    "    print(f\"metric: {metric}\")\n",
    "    df_list.append(tp.scoring._scoring._score_df(df, metric=metric, model_names=['var2', 'var3', 'model'], obs_names=['var1', 'var4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat(df_list, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.index = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a datframe with 3 months of daily data for 3 stations\n",
    "# np.random.seed(0)\n",
    "# n = 90\n",
    "# stations = ['a', 'b', 'c']\n",
    "# dates = pd.date_range('2020-01-01', periods=n, freq='D')\n",
    "# data = np.random.rand(n * len(stations), 2)\n",
    "# df = pd.DataFrame(data, index=pd.MultiIndex.from_product([dates, stations], names=['date', 'id']), columns=['tmax', 'tmin'])\n",
    "# df[\"tmin_obs\"] = df[\"tmin\"] * 0.9\n",
    "# df[\"tmax_obs\"] = df[\"tmax\"] * 0.9\n",
    "# df[\"qc_flag\"] = np.random.rand(len(df)) > 0.5\n",
    "# model_names = [\"tmax\", \"tmin\"]\n",
    "# obs_names = [\"tmax_obs\", \"tmin_obs\"]\n",
    "# # Convert values to binary for confusion matrix\n",
    "# threshold = 0.5\n",
    "# truth = df[\"tmax\"] > threshold\n",
    "# pred = df[\"tmax_obs\"] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[\"me\", \"mae\", \"rmse\"],\n",
    "grouping_keys=[\"time\", \"id\", \"qc_flag\"],\n",
    "time_grouping=\"month\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grouped_scores(\n",
    "    df,\n",
    "    metrics=[\"me\", \"mae\", \"rmse\"],\n",
    "    groupby_time=False,\n",
    "    other_grouping_keys=[\"id\", \"qc_flag\"],\n",
    "    model_names=model_names,\n",
    "    obs_names=obs_names,\n",
    "    output_index_names=model_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[(\"a\", False)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result#[0:2, 0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lats = [3.32, 4.67]\n",
    "lons = [15.02, 15.73]\n",
    "ids = [\"a\", \"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a if a is not None else b] + ['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import terrapyn as tp\n",
    "from google.cloud import bigquery\n",
    "import datetime as dt\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod = tp.bq.data.NOAA_GSOD()\n",
    "gsod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghcn = tp.bq.data.NOAA_GHCN()\n",
    "ghcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.date(2000, 1, 1)\n",
    "end_date = dt.date(2023, 12, 31)\n",
    "geom = shapely.Point(6, 43).buffer(0.2)\n",
    "# geom = shapely.Point(106.299, 16.646).buffer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghcn_stations = ghcn.stations(start_date=start_date, end_date=end_date, geom=geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghcn_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod_stations = gsod.stations(start_date=start_date, end_date=end_date, geom=geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_ids = ['USC00248783']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = gsod.stations(geom=geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = gsod.data(start_date=start_date, end_date=end_date, station_ids=stations['id'])\n",
    "df = ghcn.data(start_date=start_date, end_date=end_date, station_ids=stations['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = tp.time.groupby_time(data=df, time_dim='date', grouping='year', other_grouping_keys=['id']).agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "avg.loc[idx[:, 'FRE00171640'], 'tmax'].droplevel(1).plot.bar(y='mean', yerr='std', rot=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['elevation'].isna() | df['elevation'].eq(-999), 'elevation'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['elevation'] = df['elevation'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['elevation'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    select\n",
    "        item_id,\n",
    "        count(*) as count\n",
    "    from `{field_soil_properties_table_id}`\n",
    "    group by item_id\n",
    "    having count > 1\n",
    "\"\"\"\n",
    "query_job = client.query(query)\n",
    "n_duplicates = query_job.result().total_rows\n",
    "if n_duplicates > 0:\n",
    "    print(f\"{n_duplicates:,d} duplicates in {field_soil_properties_table_id}\")\n",
    "else:\n",
    "    print(f\"No duplicates in {field_soil_properties_table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "      with\n",
    "            stations as (\n",
    "                select\n",
    "                concat(usaf, wban) as id,\n",
    "                st_geogpoint(lon, lat) as geom,\n",
    "                parse_numeric(elev) as elevation,\n",
    "                cast(`begin` as date format 'YYYYMMDD') as start_date,\n",
    "                cast(`end` as date format 'YYYYMMDD') as end_date,\n",
    "                from `bigquery-public-data.noaa_gsod.stations`\n",
    "                where lat != 0 and lon != 0\n",
    "            )\n",
    "            select * from stations\n",
    "\"\"\"\n",
    "\n",
    "bdf = bpd.read_gbq(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NOAA_GSOD():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = bigquery.Client()\n",
    "\n",
    "    def stations(self, start_date: dt.datetime = None, end_date: dt.datetime = None, geom: shapely.Geometry = None):\n",
    "        \"\"\"\n",
    "        Get the list of weather stations from the NOAA GSOD dataset.\n",
    "\n",
    "        Args:\n",
    "            start_date: The start date for the station data.\n",
    "            end_date: The end date for the station data.\n",
    "            geom: A shapely geometry object to filter by.\n",
    "        \n",
    "        Returns:\n",
    "            A Pandas DataFrame with the station metadata.\n",
    "        \"\"\"\n",
    "    `   #\n",
    "\n",
    "\n",
    "        query = \"\"\"\n",
    "            with\n",
    "            stations as (\n",
    "                select\n",
    "                concat(usaf, wban) as id,\n",
    "                st_geogpoint(lon, lat) as geom,\n",
    "                parse_numeric(elev) as elevation,\n",
    "                cast(`begin` as date format 'YYYYMMDD') as start_date,\n",
    "                cast(`end` as date format 'YYYYMMDD') as end_date,\n",
    "                from `bigquery-public-data.noaa_gsod.stations`\n",
    "                where lat != 0 and lon != 0\n",
    "            )\n",
    "            select * from stations\n",
    "            where start_date > date(2020, 1, 1) and end_date < date(2021, 1, 1)            \"\"\"\n",
    "        return self.client.query(query).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "t_base = 10\n",
    "t_cutoff = 30\n",
    "\n",
    "tx = np.array([23])\n",
    "tm = np.array([12])\n",
    "tp.indices.growing_degree_days(tx, tm, t_base, t_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pkgutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod_info in pkgutil.walk_packages(__path__, __name__ + '.'):\n",
    "    mod = importlib.import_module(mod_info.name)\n",
    "    try:\n",
    "        names = mod.__dict__['__all__']\n",
    "    except KeyError:\n",
    "        names = [k for k in mod.__dict__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    globals().update({k: getattr(mod, k) for k in names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import shapely\n",
    "import fiona\n",
    "\n",
    "fiona.supported_drivers['KML'] = 'rw'\n",
    "\n",
    "def parse_geometry(input_string):\n",
    "    input_list = json.loads(input_string)\n",
    "    geom_flat = [\n",
    "        (pair['lng'], pair['lat'])\n",
    "        for pair in input_list\n",
    "    ]\n",
    "    return shapely.geometry.Polygon(geom_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Downloads/Geometries_Pilot_KlimRegrow_2000ha.csv\", delimiter=\";\")\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(how='all')\n",
    "# Drop duplicated rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['geometry'] = df['Geometry'].map(parse_geometry)\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[['Farm ID', 'Field ID', 'geometry']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_parquet(\"/Users/chill/software/regrowag/representative_fields/scratch/soil_sampling/Geometries_Pilot_KlimRegrow_2000ha.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf.to_file('Geometries_Pilot_KlimRegrow_2000ha_regrowformat_edit.kml', driver='KML') ## does retain client field and farm ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "fiona.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"/Users/chill/software/regrowag/representative_fields/scratch/soil_sampling/Geometries_Pilot_KlimRegrow_2000ha_regrowformat_edit.kml\", driver='KML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tp.ee.data.soilgrids(return_horizon_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"coordinates\":[[[105.16302156719024,10.387603943116673],[105.16302156719024,10.353064449494639],[105.19814120323588,10.353064449494639],[105.19814120323588,10.387603943116673],[105.16302156719024,10.387603943116673]]],\"type\":\"Polygon\"}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"coordinates\":[[[105.09969308522113,10.367838972296724],[105.09969308522113,10.327504016078379],[105.13480832876036,10.327504016078379],[105.13480832876036,10.367838972296724],[105.09969308522113,10.367838972296724]]],\"type\":\"Polygon\"}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"coordinates\":[[[105.1662707314378,10.337887984472758],[105.1662707314378,10.30473862014739],[105.19773188932533,10.30473862014739],[105.19773188932533,10.337887984472758],[105.1662707314378,10.337887984472758]]],\"type\":\"Polygon\"}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = ee.FeatureCollection(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = tp.ee.stats.principal_components(img, fc, scale=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = geemap.Map()\n",
    "m.addLayer(remapped, {}, \"remapped\")\n",
    "m.centerObject(fc, 15)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapped = tp.ee.stats.bin_and_remap(img.select('phh2o'), bins=[0,2,4,6,8,10], labels=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = tp.ee.stats.image_percentiles(img.select('soc'), fc, scale=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tp.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tp.io.kml_to_geodataframe(\"tests/data/KML_Samples.kml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tp.io.kmz_to_geodataframe(\"/Users/chill/Downloads/KML_example.kmz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(data_vars={\"var\": ((\"lat\", \"lon\", \"time\"), np.ones((1, 1, 100)))}, coords={\"lat\": [1], \"lon\": [2], \"time\": pd.date_range(\"2022-01-01\", periods=100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = pd.Timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.resample(time=\"M\", offset='1H').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> groupby_freq(ds, freq=\"M\")\n",
    "        DatasetResample, grouped over '__resample_dim__'\n",
    "        4 groups with labels 2022-01-31, ..., 2022-04-30.\n",
    "        >>> groupby_freq(ds['var'].to_dataframe(), freq=\"M\").sum()  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_lat = 4\n",
    "n_lon = 4\n",
    "n_time = 3\n",
    "data = 5 + np.random.randn(n_time, n_lat, n_lon)\n",
    "\n",
    "da = xr.DataArray(\n",
    "    data,\n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    coords={\n",
    "        \"time\": pd.date_range(\"2014-09-06\", periods=n_time),\n",
    "        \"lat\": 3 + np.arange(n_lat),\n",
    "        \"lon\": 13 + np.arange(n_lon),\n",
    "    },\n",
    "    name=\"var\",\n",
    ")\n",
    "ds = da.to_dataset()\n",
    "\n",
    "lats = [3.32, 4.67]\n",
    "lons = [15.02, 15.73]\n",
    "ids = [\"a\", \"b\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_nearest_coordinate_values(self):\n",
    "    df = tp.space.get_data_at_coords(self.ds, lats=self.lats, lons=self.lons)\n",
    "    nearest_values_point_0 = df.loc[(slice(None), 0), \"var\"].values\n",
    "    np.testing.assert_almost_equal(nearest_values_point_0, np.array([5.64768854, 4.09197592, 5.82254491]))\n",
    "    nearest_values_point_1 = df.loc[(slice(None), 1), \"var\"].values\n",
    "    np.testing.assert_almost_equal(nearest_values_point_1, np.array([4.53427025, 5.37569802, 4.6988963]))\n",
    "\n",
    "def test_missing_latitudes(self):\n",
    "    self.assertRaises(\n",
    "        ValueError,\n",
    "        tp.space.get_data_at_coords,\n",
    "        ds=self.ds,\n",
    "        lats=None,\n",
    "        lons=self.lons,\n",
    "    )\n",
    "\n",
    "def test_linear_values(self):\n",
    "    df = tp.space.get_data_at_coords(self.ds, lats=self.lats, lons=self.lons, method=\"linear\")\n",
    "    nearest_values_point_0 = df.loc[(slice(None), 0), \"var\"].values\n",
    "    np.testing.assert_almost_equal(nearest_values_point_0, np.array([5.95248557, 4.38774388, 5.11628122]))\n",
    "    nearest_values_point_1 = df.loc[(slice(None), 1), \"var\"].values\n",
    "    np.testing.assert_almost_equal(nearest_values_point_1, np.array([5.01396221, 4.63833409, 4.7608919]))\n",
    "\n",
    "def test_id_names(self):\n",
    "    df = tp.space.get_data_at_coords(self.ds, lats=self.lats, lons=self.lons, point_names=self.ids, method=\"linear\")\n",
    "    self.assertEqual(\n",
    "        list(df.index.get_level_values(\"id\")),\n",
    "        [\"a\", \"b\", \"a\", \"b\", \"a\", \"b\"],\n",
    "    )\n",
    "\n",
    "def test_point_names_dim(self):\n",
    "    df = tp.space.get_data_at_coords(\n",
    "        self.ds,\n",
    "        lats=self.lats,\n",
    "        lons=self.lons,\n",
    "        point_names=self.ids,\n",
    "        method=\"linear\",\n",
    "        point_names_dim=\"test\",\n",
    "    )\n",
    "    self.assertEqual(list(df.index.names), [\"time\", \"test\"])\n",
    "\n",
    "def test_dataset_without_time(self):\n",
    "    data = self.ds.isel(time=0).drop_vars(\"time\")\n",
    "    df = tp.space.get_data_at_coords(data, lats=self.lats, lons=self.lons, method=\"nearest\")\n",
    "    self.assertEqual(df.index.name, \"id\")\n",
    "    np.testing.assert_almost_equal(df[\"var\"].values, np.array([5.64768854, 4.53427025]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
